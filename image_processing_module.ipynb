{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./.venv/lib/python3.10/site-packages (0.2.5)\n",
      "Requirement already satisfied: openai in ./.venv/lib/python3.10/site-packages (1.35.3)\n",
      "Requirement already satisfied: langchain-openai in ./.venv/lib/python3.10/site-packages (0.1.9)\n",
      "Requirement already satisfied: pydantic in ./.venv/lib/python3.10/site-packages (2.7.4)\n",
      "Requirement already satisfied: pillow in ./.venv/lib/python3.10/site-packages (10.3.0)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.10/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./.venv/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in ./.venv/lib/python3.10/site-packages (from langchain) (0.2.9)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.venv/lib/python3.10/site-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.venv/lib/python3.10/site-packages (from langchain) (0.1.81)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.10/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.10/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in ./.venv/lib/python3.10/site-packages (from langchain) (8.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.10/site-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.10/site-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.10/site-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in ./.venv/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./.venv/lib/python3.10/site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in ./.venv/lib/python3.10/site-packages (from pydantic) (2.18.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.10/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain openai langchain-openai pydantic pillow python-dotenv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Title: Free Vintage Sofa and Traditional Chair - Perfect for Your Home!\\n\\nDescription: Don't miss out on this opportunity to elevate your seating area with a beautiful vintage-style sofa and a traditional chair, both in good condition and ready to add charm to your space. The large sofa is ideal for outdoor relaxation with its curved edges and earthy tones, while the medium-sized chair features a classic design with a smooth wood texture and comfortable upholstery. Get your hands on these high-quality items for free and enhance your home decor today!\" response_metadata={'token_usage': {'completion_tokens': 104, 'prompt_tokens': 265, 'total_tokens': 369}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-c2591b25-517c-4e5e-8e47-5b9eb617e973-0' usage_metadata={'input_tokens': 265, 'output_tokens': 104, 'total_tokens': 369}\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Optional\n",
    "from PIL import Image\n",
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "class ImageAnalysisResult(BaseModel):\n",
    "    main_objects: List[str] = Field(description=\"The primary objects in the image\")\n",
    "    additional_objects: List[str] = Field(description=\"Secondary or background objects in the image\")\n",
    "    colors: List[str] = Field(description=\"Dominant colors in the image\")\n",
    "    texture: Optional[str] = Field(description=\"Texture of the main object(s)\")\n",
    "    material: Optional[str] = Field(description=\"Material of the main object(s)\")\n",
    "    shape: Optional[str] = Field(description=\"Shape of the main object(s)\")\n",
    "    size_estimate: Optional[str] = Field(description=\"Estimated size of the main object(s)\")\n",
    "    condition: Optional[str] = Field(description=\"Condition of the item(s) in the image\")\n",
    "    brand: Optional[str] = Field(description=\"Brand name if visible in the image\")\n",
    "    style: Optional[str] = Field(description=\"Style or design of the main object(s)\")\n",
    "    functionality: Optional[str] = Field(description=\"Apparent functionality of the main object(s)\")\n",
    "    context: Optional[str] = Field(description=\"Context or setting of the image\")\n",
    "    image_quality: Optional[str] = Field(description=\"Quality of the image itself\")\n",
    "\n",
    "class OpenAIVisionProcessor:\n",
    "    def __init__(self):\n",
    "        self.chat_model = ChatOpenAI(\n",
    "            model_name=\"gpt-4o\",\n",
    "            max_tokens=1000\n",
    "        )\n",
    "        self.parser = PydanticOutputParser(pydantic_object=ImageAnalysisResult)\n",
    "\n",
    "    def encode_image(self, image_path):\n",
    "        with Image.open(image_path) as img:\n",
    "            buffered = BytesIO()\n",
    "            img.save(buffered, format=\"PNG\")\n",
    "            return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "    def process_image(self, image_path: str) -> ImageAnalysisResult:\n",
    "        base64_image = self.encode_image(image_path)\n",
    "        \n",
    "        human_message = HumanMessage(\n",
    "            content=[\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": f\"Analyze this image in detail. {self.parser.get_format_instructions()}\"\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/png;base64,{base64_image}\"\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        ai_message = self.chat_model.invoke([human_message])\n",
    "        return self.parser.parse(ai_message.content)\n",
    "    \n",
    "class ImageProcessingModule:\n",
    "    def __init__(self, vision_processor):\n",
    "        self.vision_processor = vision_processor\n",
    "\n",
    "    def process_image(self, image_path: str) -> ImageAnalysisResult:\n",
    "        return self.vision_processor.process_image(image_path)\n",
    "\n",
    "class AnalysisCombiner:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "        self.prompt = ChatPromptTemplate.from_template(\n",
    "            \"You are tasked with combining multiple image analyses into a single, coherent summary. \"\n",
    "            \"Focus on the most important and consistent information across all analyses. \"\n",
    "            \"If there are discrepancies, mention them.\\n\\n\"\n",
    "            \"Image Analyses:\\n{analyses}\\n\\n\"\n",
    "            \"Provide a combined summary of these analyses, highlighting the key features \"\n",
    "            \"of the item(s) being given away for free.\"\n",
    "        )\n",
    "        self.chain = self.prompt | self.llm\n",
    "\n",
    "    def combine_analyses(self, analyses):\n",
    "        analyses_str = \"\\n\\n\".join([f\"Analysis {i+1}:\\n{analysis.json()}\" for i, analysis in enumerate(analyses)])\n",
    "        return self.chain.invoke({\"analyses\": analyses_str})\n",
    "\n",
    "class PostGenerationService:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.7)\n",
    "        self.generate_prompt = ChatPromptTemplate.from_template(\n",
    "            \"Given the following details about an item, create a concise and appealing post for giving it away for free:\\n\"\n",
    "            \"Item details: {item_details}\\n\"\n",
    "            \"Generate a title and description for the post.\"\n",
    "        )\n",
    "        self.generate_chain = self.generate_prompt | self.llm\n",
    "\n",
    "        self.incorporate_prompt = ChatPromptTemplate.from_template(\n",
    "            \"Original post: {original_post}\\n\\n\"\n",
    "            \"User input: {user_input}\\n\\n\"\n",
    "            \"Please modify the original post to incorporate the user's input while maintaining \"\n",
    "            \"the overall structure and appeal of the post. If the user input contradicts the \"\n",
    "            \"original post, prioritize the user's information.\"\n",
    "        )\n",
    "        self.incorporate_chain = self.incorporate_prompt | self.llm\n",
    "\n",
    "    def generate_post(self, item_details):\n",
    "        return self.generate_chain.invoke({\"item_details\": item_details})\n",
    "\n",
    "    def incorporate_user_input(self, original_post, user_input):\n",
    "        return self.incorporate_chain.invoke({\n",
    "            \"original_post\": original_post,\n",
    "            \"user_input\": user_input\n",
    "        })\n",
    "\n",
    "class PostOptimizationService:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.3)\n",
    "        self.prompt = ChatPromptTemplate.from_template(\n",
    "            \"Optimize the following post for a free item to maximize engagement and clarity:\\n\"\n",
    "            \"Original post: {original_post}\\n\"\n",
    "            \"Provide an optimized version of the title and description.\"\n",
    "        )\n",
    "        self.chain = self.prompt | self.llm\n",
    "\n",
    "    def optimize_post(self, original_post):\n",
    "        return self.chain.invoke({\n",
    "            \"original_post\": original_post\n",
    "        })\n",
    "\n",
    "class Curbd:\n",
    "    def __init__(self):\n",
    "        self.image_processor = ImageProcessingModule(OpenAIVisionProcessor())\n",
    "        self.analysis_combiner = AnalysisCombiner()\n",
    "        self.post_generator = PostGenerationService()\n",
    "        self.post_optimizer = PostOptimizationService()\n",
    "\n",
    "    def process_images_and_generate_post(self, image_paths, user_input=None):\n",
    "        # Process all images\n",
    "        image_analyses = [self.image_processor.process_image(path) for path in image_paths]\n",
    "        \n",
    "        # Combine image analyses\n",
    "        combined_analysis = self.analysis_combiner.combine_analyses(image_analyses)\n",
    "        \n",
    "        # Generate initial post\n",
    "        initial_post = self.post_generator.generate_post(combined_analysis)\n",
    "        \n",
    "        # Optimize post\n",
    "        optimized_post = self.post_optimizer.optimize_post(initial_post)\n",
    "        \n",
    "        # Incorporate user input if provided\n",
    "        if user_input:\n",
    "            final_post = self.post_generator.incorporate_user_input(optimized_post, user_input)\n",
    "        else:\n",
    "            final_post = optimized_post\n",
    "        \n",
    "        return final_post\n",
    " \n",
    "\n",
    "    \n",
    "app = Curbd()\n",
    "image_paths = [\"craigslist_dataset/item_0.jpg\", \"craigslist_dataset/item_1.jpg\"]\n",
    "final_post = app.process_images_and_generate_post(image_paths)\n",
    "print(final_post)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
